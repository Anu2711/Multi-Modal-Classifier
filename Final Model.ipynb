{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c3a3c0",
   "metadata": {
    "papermill": {
     "duration": 0.007851,
     "end_time": "2023-04-17T05:00:33.749544",
     "exception": false,
     "start_time": "2023-04-17T05:00:33.741693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3640010f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:00:33.764436Z",
     "iopub.status.busy": "2023-04-17T05:00:33.763996Z",
     "iopub.status.idle": "2023-04-17T05:00:40.333213Z",
     "shell.execute_reply": "2023-04-17T05:00:40.331894Z"
    },
    "papermill": {
     "duration": 6.580244,
     "end_time": "2023-04-17T05:00:40.336248",
     "exception": false,
     "start_time": "2023-04-17T05:00:33.756004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt # plotting distribution of classes\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d40f34",
   "metadata": {
    "papermill": {
     "duration": 0.006749,
     "end_time": "2023-04-17T05:00:40.350219",
     "exception": false,
     "start_time": "2023-04-17T05:00:40.343470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining Class to Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92f028a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:00:40.367128Z",
     "iopub.status.busy": "2023-04-17T05:00:40.365837Z",
     "iopub.status.idle": "2023-04-17T05:00:40.374499Z",
     "shell.execute_reply": "2023-04-17T05:00:40.373470Z"
    },
    "papermill": {
     "duration": 0.020018,
     "end_time": "2023-04-17T05:00:40.377321",
     "exception": false,
     "start_time": "2023-04-17T05:00:40.357303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_DICT = {\n",
    "    'Sandal': 1,\n",
    "    'Bottomwear': 2,\n",
    "    'Shoes': 3,\n",
    "    'Topwear': 4,\n",
    "    'Innerwear': 5,\n",
    "    'Loungewear and Nightwear': 6,\n",
    "    'Watches': 7,\n",
    "    'Fragrance': 8,\n",
    "    'Eyewear': 9,\n",
    "    'Lips': 10,\n",
    "    'Bags': 11,\n",
    "    'Saree': 12,\n",
    "    'Wallets': 13,\n",
    "    'Scarves': 14,\n",
    "    'Jewellery': 15,\n",
    "    'Dress': 16,\n",
    "    'Ties': 17,\n",
    "    'Flip Flops': 18,\n",
    "    'Headwear': 19,\n",
    "    'Makeup': 20,\n",
    "    'Belts': 21,\n",
    "    'Socks': 22,\n",
    "    'Nails': 23,\n",
    "    'Free Gifts': 24,\n",
    "    'Apparel Set': 25,\n",
    "    'Cufflinks': 26,\n",
    "    'Accessories': 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92bd4025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:00:40.393786Z",
     "iopub.status.busy": "2023-04-17T05:00:40.392994Z",
     "iopub.status.idle": "2023-04-17T05:00:40.406978Z",
     "shell.execute_reply": "2023-04-17T05:00:40.405780Z"
    },
    "papermill": {
     "duration": 0.025235,
     "end_time": "2023-04-17T05:00:40.409617",
     "exception": false,
     "start_time": "2023-04-17T05:00:40.384382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FashionDatasetStacking(Dataset):\n",
    "    \"\"\"Fashion dataset.\"\"\"\n",
    "    def __init__(self, test=False):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.test = test\n",
    "        if self.test:\n",
    "            self.fashion_frame = pd.read_csv('/kaggle/input/uw-cs480-winter23/test.csv')\n",
    "        else:\n",
    "            self.fashion_frame = pd.read_csv('/kaggle/input/uw-cs480-winter23/train.csv')\n",
    "        self.fashion_frame = pd.get_dummies(self.fashion_frame\n",
    "                                            , columns = ['gender', 'baseColour', 'season', 'usage'])\n",
    "        self.root_dir = '/kaggle/input/uw-cs480-winter23/noisy-images/noisy-images'\n",
    "        self.transform_img = transforms.Compose(\n",
    "            [transforms.ToTensor()\n",
    "             , transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fashion_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                str(self.fashion_frame.iloc[idx, 0])+'.jpg')\n",
    "        image = plt.imread(img_name)\n",
    "        if self.test:\n",
    "            features = self.fashion_frame.iloc[idx, 2:]\n",
    "            text = self.fashion_frame.iloc[idx, 1]\n",
    "            label = self.fashion_frame.iloc[idx, 0]\n",
    "        else:\n",
    "            features = self.fashion_frame.iloc[idx, 3:]\n",
    "            text = self.fashion_frame.iloc[idx, 2]\n",
    "            label = LABEL_DICT[self.fashion_frame.iloc[idx, 1]]\n",
    "        features = np.array(features)\n",
    "        features = features.astype('float32')  \n",
    "        \n",
    "        image = self.transform_img(image.copy())\n",
    "\n",
    "        return image, features, text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a6fee",
   "metadata": {
    "papermill": {
     "duration": 0.006534,
     "end_time": "2023-04-17T05:00:40.422981",
     "exception": false,
     "start_time": "2023-04-17T05:00:40.416447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283ea35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:00:40.440216Z",
     "iopub.status.busy": "2023-04-17T05:00:40.439092Z",
     "iopub.status.idle": "2023-04-17T05:00:40.455910Z",
     "shell.execute_reply": "2023-04-17T05:00:40.454942Z"
    },
    "papermill": {
     "duration": 0.02824,
     "end_time": "2023-04-17T05:00:40.458593",
     "exception": false,
     "start_time": "2023-04-17T05:00:40.430353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FashionClassifierLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # For images\n",
    "        self.conv1 = nn.Conv2d(3, 16, (5, 3), padding='same')\n",
    "        self.conv2 = nn.Conv2d(16, 16, (5, 3), padding='same')\n",
    "        self.conv3 = nn.Conv2d(16, 32, (5, 3), padding='same')\n",
    "        self.conv4 = nn.Conv2d(32, 32, (5, 3), padding='same')\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # For text\n",
    "        self.hidden_size = 1024\n",
    "        self.embeddings = nn.Embedding(vocab_size, 50, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(50, 1024, num_layers=3, batch_first=True, dropout=0.4)\n",
    "        self.linearlstm = nn.Linear(1024, 32*20*15)\n",
    "        \n",
    "        # For categorical variables\n",
    "        self.ln1 = nn.Linear(62, 512)\n",
    "        self.ln2 = nn.Linear(512, 32*20*15)\n",
    "        \n",
    "        # for concatenated\n",
    "        self.fc1 = nn.Linear(32*20*15*3, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 27)\n",
    "        \n",
    "        # Dropouts\n",
    "        self.dp1 = nn.Dropout(p=0.25)\n",
    "        self.dp2 = nn.Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, image, features, text, offsets):\n",
    "        image = F.relu(self.conv1(image))\n",
    "        image = F.relu(self.conv2(image))\n",
    "        image = self.pool(image)\n",
    "        image = self.dp1(image)\n",
    "\n",
    "        image = F.relu(self.conv3(image))\n",
    "        image = F.relu(self.conv4(image))\n",
    "        image = self.pool(image)\n",
    "        image = self.dp2(image)\n",
    "        \n",
    "        image = torch.flatten(image, 1)\n",
    "        \n",
    "        features = self.ln1(features)\n",
    "        features = self.ln2(features)\n",
    "\n",
    "        text = self.embeddings(text)\n",
    "        lstm_out, (hidden, cell) = self.lstm(text)\n",
    "        text = self.linearlstm(hidden[-1])\n",
    "        \n",
    "        output = torch.cat((image, features, text), 1)\n",
    "        \n",
    "        output = F.relu(self.fc1(output))\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = F.relu(self.fc3(output))\n",
    "        output = F.log_softmax(self.fc4(output), 1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f9def6",
   "metadata": {
    "papermill": {
     "duration": 0.006526,
     "end_time": "2023-04-17T05:00:40.471948",
     "exception": false,
     "start_time": "2023-04-17T05:00:40.465422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the Data and Run Experiments on the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cd2fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:00:40.488090Z",
     "iopub.status.busy": "2023-04-17T05:00:40.487316Z",
     "iopub.status.idle": "2023-04-17T05:00:40.669338Z",
     "shell.execute_reply": "2023-04-17T05:00:40.667993Z"
    },
    "papermill": {
     "duration": 0.193718,
     "end_time": "2023-04-17T05:00:40.672485",
     "exception": false,
     "start_time": "2023-04-17T05:00:40.478767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "fashion_data = FashionDatasetStacking()\n",
    "fashion_test_data = FashionDatasetStacking(test=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233bfb36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:00:40.689039Z",
     "iopub.status.busy": "2023-04-17T05:00:40.688189Z",
     "iopub.status.idle": "2023-04-17T05:02:52.780950Z",
     "shell.execute_reply": "2023-04-17T05:02:52.779880Z"
    },
    "papermill": {
     "duration": 132.10485,
     "end_time": "2023-04-17T05:02:52.784320",
     "exception": false,
     "start_time": "2023-04-17T05:00:40.679470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "max_length = 14\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _,_,text,_ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(fashion_data), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "def collate_batch_LSTM(batch, testing=False):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    image_list = []\n",
    "    feature_list = []\n",
    "    for (image, features, _text, _label) in batch:\n",
    "        if testing == True:\n",
    "            label_list.append(_label)\n",
    "        else:\n",
    "            label_list.append(label_pipeline(_label))\n",
    "        encoded_text = np.zeros(max_length, dtype=int)\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        length = min(max_length, len(processed_text))\n",
    "        encoded_text[:length] = processed_text[:length]\n",
    "        \n",
    "        text_list.append(torch.tensor(encoded_text, dtype=torch.int64))\n",
    "        offsets.append(processed_text.size(0))\n",
    "        image_list.append(image)\n",
    "        feature_list.append(features)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    image_list = torch.utils.data.default_collate(image_list)\n",
    "    feature_list = torch.utils.data.default_collate(feature_list)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.utils.data.default_collate(text_list)\n",
    "    return image_list, feature_list, text_list, label_list, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791e7bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:02:52.801422Z",
     "iopub.status.busy": "2023-04-17T05:02:52.800073Z",
     "iopub.status.idle": "2023-04-17T05:02:52.810132Z",
     "shell.execute_reply": "2023-04-17T05:02:52.808848Z"
    },
    "papermill": {
     "duration": 0.021148,
     "end_time": "2023-04-17T05:02:52.812756",
     "exception": false,
     "start_time": "2023-04-17T05:02:52.791608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for batch, (image, features, text, label, offsets) in enumerate(dataloader):\n",
    "        image, features, text, label, offsets = image.to(device), features.to(device), text.to(device), label.to(device), offsets.to(device)\n",
    "\n",
    "        pred = model(image, features, text, offsets)\n",
    "        loss = loss_fn(pred, label)\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == label).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "    average_train_loss = train_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    return accuracy, average_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97cfeba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:02:52.828198Z",
     "iopub.status.busy": "2023-04-17T05:02:52.827765Z",
     "iopub.status.idle": "2023-04-17T05:02:52.836840Z",
     "shell.execute_reply": "2023-04-17T05:02:52.835558Z"
    },
    "papermill": {
     "duration": 0.020332,
     "end_time": "2023-04-17T05:02:52.839825",
     "exception": false,
     "start_time": "2023-04-17T05:02:52.819493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for image, features, text, label, offsets in dataloader:\n",
    "            image, features, text, label, offsets = image.to(device), features.to(device), text.to(device), label.to(device), offsets.to(device)\n",
    "            pred = model(image, features, text, offsets)\n",
    "            test_loss += loss_fn(pred, label).item()\n",
    "            correct += (pred.argmax(1) == label).type(torch.float).sum().item()\n",
    "    average_test_loss = test_loss / num_batches\n",
    "    accuracy = correct / size\n",
    "    return accuracy, average_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164df702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:02:52.855709Z",
     "iopub.status.busy": "2023-04-17T05:02:52.855032Z",
     "iopub.status.idle": "2023-04-17T05:02:52.861876Z",
     "shell.execute_reply": "2023-04-17T05:02:52.861050Z"
    },
    "papermill": {
     "duration": 0.016993,
     "end_time": "2023-04-17T05:02:52.864070",
     "exception": false,
     "start_time": "2023-04-17T05:02:52.847077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def experiment(model, optimizer, train_dataloader, test_dataloader, loss_fn, epochs=10):\n",
    "\n",
    "    all_train_accuracies = []\n",
    "    all_test_accuracies = []\n",
    "    for t in tqdm(range(epochs)):\n",
    "    \n",
    "        # train\n",
    "        train_accuracy, average_train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "        all_train_accuracies += [train_accuracy]\n",
    "    \n",
    "        #test\n",
    "        test_accuracy, average_test_loss = test(test_dataloader, model, loss_fn)\n",
    "        all_test_accuracies += [test_accuracy]\n",
    "    \n",
    "        print(f\"Epoch {t+1}:\\t Train accuracy: {100*train_accuracy:0.1f}%\\t Avg train loss: {average_train_loss:>6f}\\t Test accuracy: {100*test_accuracy:0.1f}%\\t Avg test loss: {average_test_loss:>6f}\")\n",
    "        \n",
    "    return all_train_accuracies, all_test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57604cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:02:52.880324Z",
     "iopub.status.busy": "2023-04-17T05:02:52.879128Z",
     "iopub.status.idle": "2023-04-17T05:02:52.886800Z",
     "shell.execute_reply": "2023-04-17T05:02:52.885699Z"
    },
    "papermill": {
     "duration": 0.01804,
     "end_time": "2023-04-17T05:02:52.889136",
     "exception": false,
     "start_time": "2023-04-17T05:02:52.871096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_batches = 512\n",
    "train_loader = DataLoader(fashion_data, shuffle=True, batch_size=num_batches, collate_fn=lambda x: collate_batch_LSTM(x, testing=False))\n",
    "# validate_loader = DataLoader(validate_set, shuffle=True, batch_size=num_batches, collate_fn=lambda x: collate_batch_LSTM(x, testing=False))\n",
    "test_loader = DataLoader(fashion_test_data, shuffle=False, batch_size=num_batches, collate_fn=lambda x: collate_batch_LSTM(x, testing=True))\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a874af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T05:02:52.904519Z",
     "iopub.status.busy": "2023-04-17T05:02:52.904054Z",
     "iopub.status.idle": "2023-04-17T11:16:44.872977Z",
     "shell.execute_reply": "2023-04-17T11:16:44.871736Z"
    },
    "papermill": {
     "duration": 22431.988418,
     "end_time": "2023-04-17T11:16:44.884268",
     "exception": false,
     "start_time": "2023-04-17T05:02:52.895850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [09:16<6:01:43, 556.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\t Train accuracy: 43.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [18:32<5:52:17, 556.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\t Train accuracy: 70.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [27:51<5:43:43, 557.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\t Train accuracy: 79.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [37:08<5:34:19, 557.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\t Train accuracy: 84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [46:32<5:26:29, 559.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\t Train accuracy: 86.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [55:51<5:17:02, 559.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\t Train accuracy: 88.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [1:05:00<5:05:46, 555.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\t Train accuracy: 90.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [1:14:13<4:56:08, 555.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\t Train accuracy: 92.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [1:23:30<4:47:08, 555.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\t Train accuracy: 92.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [1:32:51<4:38:37, 557.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\t Train accuracy: 94.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [1:42:17<4:30:40, 560.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\t Train accuracy: 95.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [1:51:52<4:23:26, 564.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\t Train accuracy: 95.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [2:01:22<4:14:46, 566.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\t Train accuracy: 96.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [2:10:48<4:05:17, 566.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\t Train accuracy: 97.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [2:20:08<3:55:04, 564.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\t Train accuracy: 97.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [2:29:31<3:45:32, 563.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:\t Train accuracy: 97.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [2:38:54<3:36:07, 563.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:\t Train accuracy: 97.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [2:48:13<3:26:10, 562.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:\t Train accuracy: 98.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [2:57:36<3:16:51, 562.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:\t Train accuracy: 98.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [3:07:01<3:07:42, 563.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:\t Train accuracy: 98.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [3:16:23<2:58:15, 562.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:\t Train accuracy: 98.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [3:25:41<2:48:28, 561.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22:\t Train accuracy: 98.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [3:35:04<2:39:13, 561.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:\t Train accuracy: 99.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [3:44:24<2:29:40, 561.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:\t Train accuracy: 99.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [3:53:41<2:19:58, 559.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:\t Train accuracy: 98.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [4:03:05<2:10:55, 561.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:\t Train accuracy: 98.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [4:12:26<2:01:33, 561.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27:\t Train accuracy: 98.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [4:21:51<1:52:28, 562.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:\t Train accuracy: 99.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [4:31:13<1:43:03, 562.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29:\t Train accuracy: 99.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [4:40:38<1:33:51, 563.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:\t Train accuracy: 99.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [4:49:57<1:24:16, 561.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:\t Train accuracy: 99.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [4:59:09<1:14:32, 559.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:\t Train accuracy: 99.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [5:08:26<1:05:08, 558.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:\t Train accuracy: 99.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [5:17:43<55:47, 557.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:\t Train accuracy: 99.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [5:27:03<46:32, 558.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:\t Train accuracy: 99.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [5:36:32<37:26, 561.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36:\t Train accuracy: 99.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [5:45:55<28:06, 562.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:\t Train accuracy: 99.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [5:55:13<18:41, 560.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38:\t Train accuracy: 99.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [6:04:35<09:21, 561.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39:\t Train accuracy: 99.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [6:13:51<00:00, 560.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40:\t Train accuracy: 99.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# batch size was 512\n",
    "\n",
    "model = FashionClassifierLSTM().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.NLLLoss()\n",
    "epochs = 40\n",
    "for t in tqdm(range(epochs)):\n",
    "    train_accuracy, average_train_loss = train(train_loader, model, loss_fn, optimizer)\n",
    "    print(f\"Epoch {t+1}:\\t Train accuracy: {100*train_accuracy:0.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79bfb7e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T11:16:44.911789Z",
     "iopub.status.busy": "2023-04-17T11:16:44.911094Z",
     "iopub.status.idle": "2023-04-17T11:16:45.183161Z",
     "shell.execute_reply": "2023-04-17T11:16:45.181704Z"
    },
    "papermill": {
     "duration": 0.289995,
     "end_time": "2023-04-17T11:16:45.186077",
     "exception": false,
     "start_time": "2023-04-17T11:16:44.896082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstm_whole_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b899a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T11:16:45.212078Z",
     "iopub.status.busy": "2023-04-17T11:16:45.211644Z",
     "iopub.status.idle": "2023-04-17T11:16:45.216629Z",
     "shell.execute_reply": "2023-04-17T11:16:45.215431Z"
    },
    "papermill": {
     "duration": 0.020834,
     "end_time": "2023-04-17T11:16:45.219004",
     "exception": false,
     "start_time": "2023-04-17T11:16:45.198170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = FashionClassifierLSTM().to(device)\n",
    "# model.load_state_dict(torch.load('/kaggle/input/lstm-model/lstm_final_model.pt'))\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c1487f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T11:16:45.245424Z",
     "iopub.status.busy": "2023-04-17T11:16:45.244955Z",
     "iopub.status.idle": "2023-04-17T11:16:45.249905Z",
     "shell.execute_reply": "2023-04-17T11:16:45.248679Z"
    },
    "papermill": {
     "duration": 0.020936,
     "end_time": "2023-04-17T11:16:45.252252",
     "exception": false,
     "start_time": "2023-04-17T11:16:45.231316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = FashionClassifierLSTM().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# loss_fn = nn.NLLLoss()\n",
    "# all_train_accuracies, all_test_accuracies = experiment(model, optimizer, train_loader, validate_loader, loss_fn, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7308908",
   "metadata": {
    "papermill": {
     "duration": 0.011618,
     "end_time": "2023-04-17T11:16:45.276056",
     "exception": false,
     "start_time": "2023-04-17T11:16:45.264438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First submission was 5 models\n",
    "Second was 100 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bd6d8d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T11:16:45.302762Z",
     "iopub.status.busy": "2023-04-17T11:16:45.301723Z",
     "iopub.status.idle": "2023-04-17T12:09:54.027099Z",
     "shell.execute_reply": "2023-04-17T12:09:54.025676Z"
    },
    "papermill": {
     "duration": 3188.741689,
     "end_time": "2023-04-17T12:09:54.029883",
     "exception": false,
     "start_time": "2023-04-17T11:16:45.288194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 Done\n",
      "Batch 2 Done\n",
      "Batch 3 Done\n",
      "Batch 4 Done\n",
      "Batch 5 Done\n",
      "Batch 6 Done\n",
      "Batch 7 Done\n",
      "Batch 8 Done\n",
      "Batch 9 Done\n",
      "Batch 10 Done\n",
      "Batch 11 Done\n",
      "Batch 12 Done\n",
      "Batch 13 Done\n",
      "Batch 14 Done\n",
      "Batch 15 Done\n",
      "Batch 16 Done\n",
      "Batch 17 Done\n",
      "Batch 18 Done\n",
      "Batch 19 Done\n",
      "Batch 20 Done\n",
      "Batch 21 Done\n",
      "Batch 22 Done\n",
      "Batch 23 Done\n",
      "Batch 24 Done\n",
      "Batch 25 Done\n",
      "Batch 26 Done\n",
      "Batch 27 Done\n",
      "Batch 28 Done\n",
      "Batch 29 Done\n",
      "Batch 30 Done\n",
      "Batch 31 Done\n",
      "Batch 32 Done\n",
      "Batch 33 Done\n",
      "Batch 34 Done\n",
      "Batch 35 Done\n",
      "Batch 36 Done\n",
      "Batch 37 Done\n",
      "Batch 38 Done\n",
      "Batch 39 Done\n",
      "Batch 40 Done\n",
      "Batch 41 Done\n",
      "Batch 42 Done\n",
      "Batch 43 Done\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "result_pred = pd.DataFrame(columns=['id', 'category'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (image, features, text, label, offsets) in enumerate(test_loader):\n",
    "        intermed_pred = pd.DataFrame(columns=['id', 'category'])\n",
    "        image, features, text, offsets = image.to(device), features.to(device), text.to(device), offsets.to(device)\n",
    "        \n",
    "        pred = torch.zeros([features.shape[0],27]).to(device)\n",
    "        for i in range(20):\n",
    "            pred += model(image, features, text, offsets)\n",
    "        \n",
    "        final_pred = pred.argmax(1)\n",
    "        \n",
    "        intermed_pred['id'] = label\n",
    "        intermed_pred['category'] = final_pred.cpu()\n",
    "        result_pred = result_pred.append(intermed_pred)\n",
    "        print('Batch {} Done'.format(batch_idx+1))\n",
    "\n",
    "result_pred['category'] = result_pred['category'].map(lambda i: list(LABEL_DICT.keys())[i])\n",
    "result_pred.to_csv('results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58b2f8",
   "metadata": {
    "papermill": {
     "duration": 0.014428,
     "end_time": "2023-04-17T12:09:54.059257",
     "exception": false,
     "start_time": "2023-04-17T12:09:54.044829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bootstrapping the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e53cd35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T12:09:54.090620Z",
     "iopub.status.busy": "2023-04-17T12:09:54.090145Z",
     "iopub.status.idle": "2023-04-17T12:09:54.095766Z",
     "shell.execute_reply": "2023-04-17T12:09:54.094478Z"
    },
    "papermill": {
     "duration": 0.024494,
     "end_time": "2023-04-17T12:09:54.098472",
     "exception": false,
     "start_time": "2023-04-17T12:09:54.073978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fashion_data = FashionDatasetStacking()\n",
    "# fashion_test_data = FashionDatasetStacking(test=True)\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2d4594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T12:09:54.131509Z",
     "iopub.status.busy": "2023-04-17T12:09:54.130164Z",
     "iopub.status.idle": "2023-04-17T12:09:54.136000Z",
     "shell.execute_reply": "2023-04-17T12:09:54.134983Z"
    },
    "papermill": {
     "duration": 0.024692,
     "end_time": "2023-04-17T12:09:54.138275",
     "exception": false,
     "start_time": "2023-04-17T12:09:54.113583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch_size = 512\n",
    "\n",
    "# test_loader = DataLoader(fashion_test_data, shuffle=False, batch_size=batch_size, collate_fn=lambda x: collate_batch_LSTM(x, testing=True))\n",
    "# num_models = 5\n",
    "# num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "616ba3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T12:09:54.170097Z",
     "iopub.status.busy": "2023-04-17T12:09:54.169363Z",
     "iopub.status.idle": "2023-04-17T12:09:54.174924Z",
     "shell.execute_reply": "2023-04-17T12:09:54.174071Z"
    },
    "papermill": {
     "duration": 0.02431,
     "end_time": "2023-04-17T12:09:54.177277",
     "exception": false,
     "start_time": "2023-04-17T12:09:54.152967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# model_list = []\n",
    "# for i in range(num_models):\n",
    "#     model = FashionClassifierLSTM().to(device)\n",
    "#     model_list.append(model)\n",
    "\n",
    "# for i in range(num_models):\n",
    "#     model = model_list[i]\n",
    "#     generator1 = torch.Generator()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "#     loss_fn = nn.NLLLoss()\n",
    "#     train_loader = DataLoader(fashion_data, batch_size=batch_size\n",
    "#                           , collate_fn=lambda x: collate_batch_LSTM(x, testing=False)\n",
    "#                           , sampler=torch.utils.data.RandomSampler(fashion_data, replacement=True, num_samples=len(fashion_data), generator=None))\n",
    "#     for t in tqdm(range(num_epochs)):\n",
    "#         # train\n",
    "#         train_accuracy, average_train_loss = train(train_loader, model, loss_fn, optimizer)\n",
    "#         print(f\"Epoch {t+1}:\\t Train accuracy: {100*train_accuracy:0.1f}%\\t Avg train loss: {average_train_loss:>6f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeb49f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T12:09:54.209186Z",
     "iopub.status.busy": "2023-04-17T12:09:54.208538Z",
     "iopub.status.idle": "2023-04-17T12:09:54.212249Z",
     "shell.execute_reply": "2023-04-17T12:09:54.211454Z"
    },
    "papermill": {
     "duration": 0.022683,
     "end_time": "2023-04-17T12:09:54.214802",
     "exception": false,
     "start_time": "2023-04-17T12:09:54.192119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(num_models):\n",
    "#     model = model_list[i]\n",
    "#     torch.save(model.state_dict(), f\"model{i+1}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a96f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T12:09:54.246745Z",
     "iopub.status.busy": "2023-04-17T12:09:54.246293Z",
     "iopub.status.idle": "2023-04-17T12:09:54.251988Z",
     "shell.execute_reply": "2023-04-17T12:09:54.250779Z"
    },
    "papermill": {
     "duration": 0.024619,
     "end_time": "2023-04-17T12:09:54.254655",
     "exception": false,
     "start_time": "2023-04-17T12:09:54.230036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(num_models):\n",
    "#     model_list[i].eval()\n",
    "# result_pred = pd.DataFrame(columns=['id', 'category'])\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_idx, (image, features, text, label, offsets) in enumerate(test_loader):\n",
    "#         intermed_pred = pd.DataFrame(columns=['id', 'category'])\n",
    "#         image, features, text, offsets = image.to(device), features.to(device), text.to(device), offsets.to(device)\n",
    "        \n",
    "#         pred = torch.zeros([features.shape[0],27]).to(device)\n",
    "#         for i in range(num_models):\n",
    "#             pred += model(image, features, text, offsets)\n",
    "        \n",
    "#         final_pred = pred.argmax(1)\n",
    "        \n",
    "#         intermed_pred['id'] = label\n",
    "#         intermed_pred['category'] = final_pred.cpu()\n",
    "#         result_pred = result_pred.append(intermed_pred)\n",
    "#         print('Batch {} Done'.format(batch_idx+1))\n",
    "\n",
    "# result_pred['category'] = result_pred['category'].map(lambda i: list(LABEL_DICT.keys())[i])\n",
    "# result_pred.to_csv('results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a616d39b",
   "metadata": {
    "papermill": {
     "duration": 0.014471,
     "end_time": "2023-04-17T12:09:54.284062",
     "exception": false,
     "start_time": "2023-04-17T12:09:54.269591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Written Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c47bc",
   "metadata": {
    "papermill": {
     "duration": 0.014165,
     "end_time": "2023-04-17T12:09:54.312785",
     "exception": false,
     "start_time": "2023-04-17T12:09:54.298620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* <b>Categorical attributes</b>: For the training loop, three linear layers to combine the categorical attributes were used. \n",
    "* <b>Noisy text description</b>: For text classification, an LSTM was used. LSTM units are more expressive and can control the content of their memory by utilizing gates. Prior to using the LSTM gates, the text is embedded using nn.embedding to convert it into a tensor of integers and make classification easier. Additionally, since the longest text description had 14 words, all the text is padded to a maximum length of 14.\n",
    "* <b>Image Classification</b>: To take advantage of the images for classification, a 5x3 channel with maximal channels was implemented. This performed well because the greater the number of channels the greater is the capacity of the network. Additionally a 5x3 channel was used since a smaller channel have lesser parameters, which increases the generalization of the model. Moreover, dropouts have also been implemented twice since they help achieve better generalisation, despite it making the model learn slowly.\n",
    "* <b>Ensemble learning</b>: In terms of ensemble techniques, two techniques were used: Stacking and Bagging. The models to extract features from the categorical attributes, text description and the images were concatenated and later passed through multiple layers to extract important features from the concatenated model. Secondly, for bagging, 5 models were trained on separate data by repeatedly sampling from the training data. Then, the vector of probabilities outputted by each model were added and the predictions are the classes with the maximum probabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25774.719864,
   "end_time": "2023-04-17T12:09:56.726694",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-17T05:00:22.006830",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
